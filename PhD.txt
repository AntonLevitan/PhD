1) Setup ssh private/public keys

    --- NOT NEEDED FOR NOW ---

	ssh-keygen generates a private/public key pair
	stored in ~/.ssh
	copy folder to another machine for remote access to sites/servers

2) Configure ssh pair auth for nova

    --- NOT NEEDED FOR NOW ---

	TODO:
	test config of pairs
	see if can be done with rack-pace-01 as well


4) Learn version control

    --- DONE FOR NOW ---

	TODO:
	Summary


5) GitHub

	setup ssh keypairs in every workstation for access

	PhD:

		created repository PhD for this file and its possible future branches

	RNASeq:

		created an RNASeq repository
		pushing every day from the workstation

	Ontotype:

		created a pombe repository
		pushing every day from the workstation

		TODO:
		rename if working on other organisms

    Transposon:

        created a transposon repository with Vlad's pipeline and my own
        My pipeline runs Sc and Cg analysis well

6) Python setup

    Base Anaconda3 installation
	
	conda config --add channels defaults
	conda config --add channels bioconda
	conda config --add channels conda-forge
	
	conda create -n <environment name> python=2.7
	conda activate <environment name>

	conda install goatools, pysam, gffutils, biopython, pandas, numpy, matplotlib, scikit-learn, scipy, htseq-count
	
	conda install samtools, bamtools, cutadapt, sra-tools, bowtie2, fastqc, STAR

7) IDEs/text editors config

	TODO:
	check other text editors


		Visual Studio Code

			--- Not bad, lacks functionality. Plugins are awkward. ---

			Create personal snippets:

				File -> Preferences -> User snippets

			Enable Python linting:

				changed the majority of errors to "warning" / "information" as the linters were flagging too many
				
				e: error
				f: fatal
				w: warning

				File -> Preferences -> Settings -> search for linting
					
					mypy- significant dependencies (Python3) changes
					pep8
					flake8
			
			Useful Plugins:

				Python extensions

				neuron (IPE):

					open output pane: ctrl+k -> ctrl+v 
					select relevant part of code 
					send to output pane: alt+enter

				Jupyter:

					add #%% to start a Jupyter cell

			Display presets:

				lab laptop: (

					specs: [Dell, 15", 1080p]
					display: native
					color scheme: Monokai

				);

				lab monitor: (

					specs: [Dell, 24", 1080p]
					display: dual
					color scheme: Monokai

				);	

			
		PyCharm
		
            --- The best one yet. Consider renewing license ---

			Layout:

				Scientific view
				Python Console
				Special Variables
				Terminal

			Display presets:

				Monokai adjusted:

					removed italics (editor->color_scheme->python)

				lab laptop: (

					specs: [Dell, 15", 1080p]
					display: native
					font: DejaVu Sans Mono
					font_size: 14
					line_spacing: 1.3
					color scheme: Monokai adjusted

				);

				lab monitor: (

					specs: [Dell, 24", 1080p]
					display: dual
					font: DejaVu Sans Mono
					line_spacing: 1.3
					color scheme: Monokai adjusted

				);

		Spyder

            --- Not good enough ---

			TODO:
			review interpeter
			check plugins
			optimize display
			optimize layout
			check updates


		Sublime text

			TODO:
			check plugins for Sublime Text
			see if paid account necessary
			verify installation- plugins aren't working			

			Display presets:

				lab laptop: (

					specs: [Dell, 15", 1080p]
					display: native
					font: INCONSOLATA
					font_size: 10
					color scheme: Monokai

				);

				lab monitor: (

					specs: [Dell, 24", 1080p]
					display: dual
					font: INCONSOLATA
					font_size: 10
					color scheme: Monokai

				);


8) NGS pipeline

	TODO:
	Add reference genome indices folder for bowtie2

9) Administration

	TODO:
	
	Courses registration:

		Life Sciences:

			Courses: (

				Concepts in statistics
				Intro to Bioinformatics
				Methods in Bioinformatics (lab)
				Python for Biologists

			);

		Computer Science:

			Courses: (

				Roded's seminar

			);


10) RNA Seq Project

	TODO:
	plot scaled version according to chromosome length
	vertical alignment of chromosomes
	document changes
	account for haplotype B

	Setup:

	install biostar conda env- bioinfo:

		Python 3.6 conda-forge

		curl http://data.biostarhandbook.com/install/conda.txt | xargs conda install -y

		contains:

			entrez-direct
			parallel=20180922
			bwa
			htslib
			bowtie2
			emboss
			bedtools
			samtools
			bamtools
			sra-tools
			cutadapt
			seqtk
			datamash
			bcftools
			freebayes
			subread
			bioawk
			hisat2
			bbmap
			trimmomatic
			fastqc
			snpeff
			picard
			blast
			perl-list-moreutils

		install multiqc for comparative reports of sequencing data -- not sure how useful

	Bash pipeline:

		TODO:
		rewrite for A22

		https://github.com/joshuamwang/RNA-Seq_Analysis

		CA sample RNA Seq data:
			
			https://drive.google.com/uc?id=1AP_xnwmqXobrquf7kHYEOdo0FtI9h7fo&export=download
		
		fastqc quialty control:

			fastqc CA_fastq.gz

		download and extract reference genome to a subfolder:

			mkdir genome
			cd genome
			wget http://candidagenome.org/download/sequence/C_albicans_SC5314/Assembly21/current/C_albicans_SC5314_A21_current_chromosomes.fasta.gz
			gunzip C_albicans_SC5314_A21_current_chromosomes.fasta.gz
			cd ..

		creating a genome index in STAR:

			STAR --runThreadN 12 --runMode genomeGenerate --genomeDir genome --genomeFastaFiles genome/C_albicans_SC5314_A21_current_chromosomes.fasta --sjdbGTFtagExonParentTranscript ID
			Note: removed '$' from original pipeline

		align in STAR

			STAR --runThreadN 12 --outSAMstrandField intronMotif --genomeDir genome --readFilesIn CA.fastq.gz --outSAMtype BAM SortedByCoordinate --readFilesCommand zcat --alignIntronMin 30 --alignIntronMax 1000 
			Note: Remove the "--readFilesCommand zcat" flag if the fastq file is not gzipped.
			Note: changed CA.fastq.gz to Ca_fastq.gz
			
		output:

			ls
			Aligned.sortedByCoord.out.bam  <-- alignment file
			Log.final.out                  <-- alignment statistics
			Log.out
			Log.progress.out
			SJ.out.tab

		change name of .bam:

			mv Aligned.sortedByCoord.out.bam CA.bam

		index the alignment:

			samtools index CA.bam
			
		examine in IGV:
		
			Select Genomes -> Load Genomes from File -> select C_albicans_SC5314_A21_current_chromosomes.fasta
			Click File from the upper left corner -> Load from file -> select the CA.bam file.
			Note: changed order from the original. genome first, file after.

		count reads assigned to each feature:

			obtain C. albicans gff file:

				wget http://candidagenome.org/download/gff/C_albicans_SC5314/Assembly21/C_albicans_SC5314_A21_current_features.gff

			run HTseq:

				htseq-count -t gene -i ID -f bam CA.bam C_albicans_SC5314_A21_current_features.gff > CA_count.txt
				Note: added --stranded=no flag as most sequences are unstranded. increased mapping to features quantity by orders of magnitude in some cases


	Plotting reads (Python): 
	
		adaptation to assembly 22 (A22) instead of translation from A21:

			filtered reference A22 genome for haplotype A only
			mapped reads to features and counted 
			filtered out haplotype B features from count file

		transforming into log2

		smoothing plot with moving averages of 10 and 100 features:

			python translate_features for single feature log2(reads)
			python translate_features --ma10 for moving average of 10 features
			python translate_features --ma100 for moving average of 100 features

		normalizing the reads by a matching normalization scheme (feature by feature) from the reference data
		
			more info: https://ro-che.info/articles/2016-11-28-rna-seq-normalization	

		added rpk rpm rpkm tpm normalizations schemes

		plotting as a barchart for chromosome
		
		saving tabular data as .xlsx 
		
		saving plots as .png

		

11) Ontotype Genetic Interactions Project

	TODO:
	memory limitation doesn't allow for --cv
    doesn't run Python3 on nova due to lack of goatools

	take apart- understand every function
	add stop points with intermediate outputs

	taking apart and translating the code:
		
		download_data:

			Python3 tranlation:

				instead import StringIO -> from io import BytesIO
				from urllib.request import urlretrieve
				instead import urllib2 -> from urllib.request import urlopen
				instead of 'w' -> 'wb'

				added try/except to all of the above for dual compatibility

			script provides 3 options for downloading data depending on their compression
			download_file allows to choose the appropriate compression and checks for data file presence
			downloads the data
			downloads :

				into Data/:

					gene ontology: go-basic.obo
					gene2go.gz
					.gene_info for each species
					costanzo supplementary data

			
		read_data:

			read ontology from go-basic.obo
			read interactions from constanzo file, columns:

				0: gene a
				2: gene b
				4: Genetic interaction score
				6: p-value
			
		generate_phenotype:

			added random_state to RandomForestClassifier

		cross_validate:

			added random_state to RandomForestClassifier
			added random_state to StratifiedKFold
		
		genotype_to_phenotype:
		
			-o generates ontotype.txt

    apply methodology on different organisms:

		S. pombe:

			Ideas:

                -- Mostly not relevant ---

				understand the hierarchical model of pombe article.
				
				ortho-essential genes have higher gene interactions

				check our data for gene interactions in essential and non-essential genes

				run ontotype model on the different hierarchical groups mentioned:

					protein complexes; r = 0.46
					biological processes; r = 0.16
					distinct biological processes; r = 0.03

				comparison with S. cerevisiae interactions; r = 0.72: global trends for eukaryots? 

				similarity score threshold and then clustering to identify modules, table S2

				E-MAP (pombe) uses a different metric (S score) than cerevisiae (SGA). those scoring systems are highly correlated: figure S5A

				hierarchical clustering (supplemental experimental procedures) -> GO analysis for enrichment

				cerevisiae data scaled: dataset S7

			Article: 
				
				https://medschool.ucsd.edu/som/medicine/research/labs/ideker/publications/Documents/ryan_MolCell_2012.pdf

			Steps for adapting code:

				transformed pombe database of GI (m x n matrix) into list

				revised code to allow for pombe GO annotations http://www.geneontology.org/page/download-go-annotations (pombe)

				possible to access any organism from that site in the same format

				completed code adaptation by removing all references to species.json

				managed to generate results- AUCs of 0.64 (as Sc) and up, with increasingly more stringent cut-offs of similarity and interactions score

        Started over:

            TODO: consider how to filter pombe data

            Not considering similarity score- irrelevant.
            Regression CV showed 0.16 Pearson's R, with highly significant p value
            Testing similar regression on Sc.

		C. albicans

	apply cross-species methodology

12) Transposon Project

	Notes:
		TN pipeline is written in python2
		installed all relevant packages in this version
		fixed numpy problem that arose from default python installation of ubuntu
			https://github.com/conda/conda/issues/6018
		created new bioinfo virtual environment with python 3.6 using anaconda2
		there is no pysam for windows
		very-fast and very-sensitive are very similar in their alignment
		wrapped the bash pipeline in a python script

	TODO:
		Add classifier to the main script
		Think about the possibility of adding filtering and sorting mapped/unmapped reads
		Add downloads of dependencies :
		    reference genomes, gff files, translation of genes lists (naming conventions), training sets.

	Pipeline:
		
		1) get reference genome

		2) create bowtie2 index for reference genome

			bowtie2-build genome.fsa 'name of genome'
				
				returns multiple .bt2 files

			bowtie2-inspect -n 'name of genome'

				prints sequence to console
			
			can export bowtie2 indexes to a directory

				export 
				BOWTIE2_INDEXES=/path/to/my/bowtie2/databases/
				cp *.bt2 $BOWTIE2_INDEXES

			to use the index when mapping use '-x'

		3) map reads

		trim TN sequences
		cutadapt --cores=6 -g TGCATGCGTCAATTTTACGCAGACTATCTTTCTA -o DMSO_trimmed.fastq DMSO.fastq --discard-untrimmed --overlap 20

		bowtie2 -p 8 --end-to-end --very-fast -x sc -U FreadI1_trimmed.fastq -S FreadI1_trimmed.sam
		for paired end alignment add '--fr' and replace -1 and -2 with -U
		
			bowtie2
			-p plus the 'number of threads'
			--end-to-end means 'global'
			--sensitive is default (doesn't show significant improvement)

			store unmapped reads to a separate .fastq file for further analysis

				bowtie2 -p 8 --end-to-end --very-fast -x sp -U FreadI1_trimmed.fastq --un ./unmapped_both_ends.fastq --al ./mapped_both_ends.fastq 
				--un-conc --al-conc for paired ends

		4) change the format to .bam
			
			samtools view -Sb input.sam > output.bam 
		
		5) samtools sort input.bam output_sorted.bam

			sort the .bam file
		
		6) samtools index output_sorted.bam

			index the .bam file

		7) counting and sorting unique sequences by number of appearance 

			samtools view unmapped_FreadI1_trimmed_sorted.bam | cut -f 10 | sort | uniq -c | sort -nr > unmapped_sorted_reads.txt

			blastn of top 20 returned: 17 reads matching various cloning vectors, 2 reads matching Hermes transposase and 1 read matching an expression vector    

		8) mapping the hits and their reads to chromosomes on a reference genome

		9) generating classifier features using .gff annotation file and the generated hitmap

		10) runs the classifier:

		        requires manual generation of training set.


